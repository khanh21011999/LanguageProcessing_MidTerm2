{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MFCC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lấy mfcc của tất cả các file trong dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy mfcc của tất cả các file wav trong wav\n",
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=14):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot biểu đồ predict/true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCM(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('test')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('true')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load cothe dataset\n",
      "Load chungta dataset\n",
      "Load duoc dataset\n",
      "Load nguoi dataset\n",
      "Load trong dataset\n"
     ]
    }
   ],
   "source": [
    "class_names = ['cothe', 'chungta', 'duoc', 'nguoi','trong']\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join('data',cname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "100\n",
      "105\n",
      "100\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset['cothe']))\n",
    "print(len(dataset['chungta']))\n",
    "print(len(dataset['duoc']))\n",
    "print(len(dataset['nguoi']))\n",
    "print(len(dataset['trong']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load chungta testDataSet\n",
      "Load duoc testDataSet\n",
      "Load trong testDataSet\n",
      "Load nguoi testDataSet\n",
      "Load cothe testDataSet\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "{'cothe': 5, 'chungta': 5, 'duoc': 5, 'nguoi': 5, 'trong': 5}\n"
     ]
    }
   ],
   "source": [
    "testClass_names = ['chungta', 'duoc', 'trong', 'nguoi', 'cothe']\n",
    "n_testDataSet = {'cothe': 0, 'chungta': 0, 'duoc': 0, 'nguoi': 0,'trong': 0}\n",
    "testDataSet = {}\n",
    "for cname in testClass_names:\n",
    "    print(f\"Load {cname} testDataSet\")\n",
    "    testDataSet[cname] = get_class_data(os.path.join('test', cname))\n",
    "    n_testDataSet[cname] = len(testDataSet[cname])\n",
    "print(len(testDataSet['chungta']))\n",
    "print(len(testDataSet['duoc']))\n",
    "print(len(testDataSet['trong']))\n",
    "print(len(testDataSet['nguoi']))\n",
    "print(len(testDataSet['cothe']))\n",
    "print(n_testDataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "80\n",
      "84\n",
      "80\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "trainset = {}\n",
    "testset = {}\n",
    "n_test = {'cothe': 0, 'chungta': 0, 'duoc': 0, 'nguoi': 0,'trong': 0}\n",
    "for cname in class_names:\n",
    "    n = len(dataset[cname])\n",
    "    n_train = math.floor(n*0.8)\n",
    "    trainset[cname] = dataset[cname][:n_train]\n",
    "    testset[cname] = dataset[cname][n_train:]\n",
    "    n_test[cname] += len(testset[cname])\n",
    "    \n",
    "print(len(trainset['cothe']))\n",
    "print(len(trainset['chungta']))\n",
    "print(len(trainset['duoc']))\n",
    "print(len(trainset['nguoi']))\n",
    "print(len(trainset['trong']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit kmeans trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (14257, 1)\n",
      "centers (14, 1)\n",
      "centers (14, 1)\n",
      "KMeans(n_clusters=14, n_init=50, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in trainset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "print(kmeans)\n",
    "fileNameKmeans = 'kmeans.sav'\n",
    "pickle.dump(kmeans, open(fileNameKmeans, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cname in class_names:\n",
    "    trainset[cname] = list([kmeans.predict(v).reshape(-1, 1) for v in trainset[cname]])\n",
    "    testset[cname] = list([kmeans.predict(v).reshape(-1, 1) for v in testset[cname]])\n",
    "for cname in testClass_names:\n",
    "    testDataSet[cname] = list([kmeans.predict(v).reshape(-1, 1) for v in testDataSet[cname]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'có thể' 4x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class cothe\n",
      "(4501, 1) [34, 31, 56, 39, 44, 40, 46, 35, 45, 47, 37, 56, 36, 31, 39, 35, 42, 30, 30, 37, 36, 39, 26, 34, 47, 36, 41, 34, 26, 30, 25, 27, 16, 39, 27, 52, 25, 27, 20, 22, 36, 53, 44, 44, 28, 57, 53, 36, 37, 30, 34, 38, 51, 43, 40, 47, 38, 44, 102, 44, 52, 56, 35, 37, 39, 25, 41, 52, 43, 33, 49, 59, 35, 42, 40, 37, 40, 35, 36, 28, 45, 44, 23, 30, 48, 35, 32, 35, 35, 26, 36, 43, 45, 62, 165, 163, 179, 165, 158] 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1      -11236.2083             +nan\n",
      "         2       -8061.2830       +3174.9253\n",
      "         3       -7035.6852       +1025.5978\n",
      "         4       -6801.1138        +234.5715\n",
      "         5       -6705.6262         +95.4876\n",
      "         6       -6659.4709         +46.1553\n",
      "         7       -6599.8659         +59.6050\n",
      "         8       -6468.8281        +131.0378\n",
      "         9       -6401.4080         +67.4201\n",
      "        10       -6249.9008        +151.5072\n",
      "        11       -6183.5637         +66.3371\n",
      "        12       -6178.4992          +5.0645\n",
      "        13       -6175.1820          +3.3172\n",
      "        14       -6172.6610          +2.5210\n",
      "        15       -6169.7157          +2.9453\n",
      "        16       -6164.2804          +5.4353\n",
      "        17       -6155.4603          +8.8201\n",
      "        18       -6146.2674          +9.1928\n",
      "        19       -6141.7276          +4.5398\n",
      "        20       -6138.1080          +3.6196\n",
      "        21       -6134.8941          +3.2139\n",
      "        22       -6133.9149          +0.9792\n",
      "        23       -6133.3603          +0.5547\n",
      "        24       -6132.9596          +0.4006\n",
      "        25       -6132.6643          +0.2953\n",
      "        26       -6132.4471          +0.2172\n",
      "        27       -6131.9108          +0.5363\n",
      "        28       -6129.5140          +2.3968\n",
      "        29       -6128.1227          +1.3912\n",
      "        30       -6127.7121          +0.4106\n",
      "        31       -6127.5443          +0.1678\n",
      "        32       -6127.4693          +0.0750\n",
      "        33       -6127.4314          +0.0379\n",
      "        34       -6127.4106          +0.0208\n",
      "        35       -6127.3987          +0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        36       -6127.3915          +0.0072\n"
     ]
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=4*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "\n",
    "Xbn = np.concatenate(trainset['cothe'])\n",
    "lengths = list([len(x) for x in trainset['cothe']])\n",
    "print(\"training class\", 'cothe')\n",
    "print(Xbn.shape, lengths, len(lengths))\n",
    "hmm.fit(Xbn, lengths=lengths)\n",
    "models['cothe'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models cho 'đã' 2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhmm = hmmlearn.hmm.MultinomialHMM(n_components=2*3, random_state=0, n_iter=1000, verbose=True, init_params=\\'e\\', params=\\'ste\\')\\nhmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0 ])\\nhmm.transmat_ =np.array([\\n    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0],\\n    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0],\\n    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0],\\n    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1],\\n    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\\n    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],])\\n\\nXct = np.concatenate(trainset[\\'da\\'])\\nlengths = list([len(x) for x in trainset[\\'da\\']])\\nprint(\"training class\", \\'da\\')\\nprint(Xct.shape, lengths, len(lengths))\\nhmm.fit(Xct, lengths=lengths)\\nmodels[\\'da\\'] = hmm\\nprint(\"Training done\")'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=2*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0 ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],])\n",
    "\n",
    "Xct = np.concatenate(trainset['da'])\n",
    "lengths = list([len(x) for x in trainset['da']])\n",
    "print(\"training class\", 'da')\n",
    "print(Xct.shape, lengths, len(lengths))\n",
    "hmm.fit(Xct, lengths=lengths)\n",
    "models['da'] = hmm\n",
    "print(\"Training done\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'chúng ta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -8271.5705             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class chungta\n",
      "(3266, 1) [41, 46, 47, 36, 43, 34, 36, 42, 36, 40, 37, 36, 30, 40, 36, 41, 36, 37, 36, 42, 40, 39, 35, 38, 38, 41, 36, 44, 38, 59, 49, 37, 43, 35, 52, 42, 50, 48, 46, 54, 55, 47, 45, 38, 39, 38, 42, 38, 43, 33, 35, 32, 42, 32, 41, 34, 40, 37, 35, 37, 47, 31, 34, 36, 34, 31, 43, 30, 37, 54, 42, 40, 75, 45, 51, 57, 43, 41, 39, 37] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2       -5558.3168       +2713.2537\n",
      "         3       -4612.2937        +946.0231\n",
      "         4       -4303.7596        +308.5341\n",
      "         5       -4191.5242        +112.2354\n",
      "         6       -4134.2702         +57.2540\n",
      "         7       -4091.8013         +42.4689\n",
      "         8       -4060.4839         +31.3174\n",
      "         9       -4039.7614         +20.7224\n",
      "        10       -4026.4939         +13.2676\n",
      "        11       -4018.5230          +7.9709\n",
      "        12       -4013.8090          +4.7140\n",
      "        13       -4010.8374          +2.9716\n",
      "        14       -4008.7758          +2.0616\n",
      "        15       -4007.1677          +1.6081\n",
      "        16       -4005.7134          +1.4542\n",
      "        17       -4004.1600          +1.5535\n",
      "        18       -4002.3590          +1.8010\n",
      "        19       -4000.3585          +2.0006\n",
      "        20       -3998.0150          +2.3434\n",
      "        21       -3994.9080          +3.1071\n",
      "        22       -3990.4830          +4.4250\n",
      "        23       -3984.4733          +6.0097\n",
      "        24       -3977.8844          +6.5889\n",
      "        25       -3972.5701          +5.3142\n",
      "        26       -3969.3005          +3.2696\n",
      "        27       -3967.5605          +1.7401\n",
      "        28       -3966.5904          +0.9700\n",
      "        29       -3965.9076          +0.6828\n",
      "        30       -3965.2918          +0.6158\n",
      "        31       -3964.6560          +0.6358\n",
      "        32       -3963.9661          +0.6899\n",
      "        33       -3963.2029          +0.7632\n",
      "        34       -3962.3362          +0.8667\n",
      "        35       -3961.3272          +1.0090\n",
      "        36       -3960.2252          +1.1020\n",
      "        37       -3959.1990          +1.0261\n",
      "        38       -3958.3465          +0.8525\n",
      "        39       -3957.6495          +0.6971\n",
      "        40       -3957.0501          +0.5994\n",
      "        41       -3956.4911          +0.5590\n",
      "        42       -3955.9224          +0.5687\n",
      "        43       -3955.2912          +0.6312\n",
      "        44       -3954.5296          +0.7616\n",
      "        45       -3953.5622          +0.9673\n",
      "        46       -3952.3774          +1.1849\n",
      "        47       -3951.1085          +1.2688\n",
      "        48       -3949.9348          +1.1737\n",
      "        49       -3948.8987          +1.0361\n",
      "        50       -3947.8537          +1.0450\n",
      "        51       -3946.3618          +1.4920\n",
      "        52       -3943.2565          +3.1053\n",
      "        53       -3936.6490          +6.6075\n",
      "        54       -3926.2403         +10.4086\n",
      "        55       -3916.8579          +9.3825\n",
      "        56       -3912.7109          +4.1470\n",
      "        57       -3911.6520          +1.0588\n",
      "        58       -3911.4421          +0.2099\n",
      "        59       -3911.3745          +0.0676\n",
      "        60       -3911.3205          +0.0541\n",
      "        61       -3911.2617          +0.0588\n",
      "        62       -3911.1931          +0.0686\n",
      "        63       -3911.1077          +0.0854\n",
      "        64       -3910.9939          +0.1138\n",
      "        65       -3910.8441          +0.1498\n",
      "        66       -3910.6804          +0.1637\n",
      "        67       -3910.5520          +0.1284\n",
      "        68       -3910.4771          +0.0748\n",
      "        69       -3910.4361          +0.0410\n",
      "        70       -3910.4101          +0.0261\n",
      "        71       -3910.3906          +0.0195\n",
      "        72       -3910.3745          +0.0161\n",
      "        73       -3910.3603          +0.0142\n",
      "        74       -3910.3474          +0.0129\n",
      "        75       -3910.3354          +0.0120\n",
      "        76       -3910.3241          +0.0113\n",
      "        77       -3910.3135          +0.0106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        78       -3910.3034          +0.0101\n",
      "        79       -3910.2939          +0.0095\n"
     ]
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=5*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "Xct = np.concatenate(trainset['chungta'])\n",
    "lengths = list([len(x) for x in trainset['chungta']])\n",
    "print(\"training class\", 'chungta')\n",
    "print(Xct.shape, lengths, len(lengths))\n",
    "hmm.fit(Xct, lengths=lengths)\n",
    "models['chungta'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'được' 4x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -4689.2294             +nan\n",
      "         2       -3287.9123       +1401.3170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class duoc\n",
      "(1856, 1) [25, 20, 19, 17, 14, 22, 21, 23, 23, 30, 15, 18, 21, 30, 19, 20, 21, 30, 22, 14, 17, 23, 23, 19, 21, 18, 18, 20, 38, 21, 22, 35, 29, 18, 19, 22, 42, 22, 20, 24, 22, 21, 22, 22, 44, 29, 18, 14, 20, 24, 22, 19, 41, 24, 20, 18, 16, 20, 18, 21, 22, 30, 17, 21, 19, 16, 19, 18, 19, 16, 20, 14, 17, 16, 32, 26, 28, 24, 25, 25, 29, 21, 15, 17] 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3       -2854.7074        +433.2049\n",
      "         4       -2685.9563        +168.7510\n",
      "         5       -2616.0288         +69.9275\n",
      "         6       -2568.3180         +47.7108\n",
      "         7       -2522.8631         +45.4549\n",
      "         8       -2482.7672         +40.0959\n",
      "         9       -2447.7714         +34.9958\n",
      "        10       -2420.2186         +27.5528\n",
      "        11       -2404.1584         +16.0602\n",
      "        12       -2395.2353          +8.9231\n",
      "        13       -2389.4213          +5.8140\n",
      "        14       -2385.7873          +3.6340\n",
      "        15       -2383.8428          +1.9445\n",
      "        16       -2382.7132          +1.1296\n",
      "        17       -2381.9218          +0.7914\n",
      "        18       -2381.2922          +0.6296\n",
      "        19       -2380.7532          +0.5389\n",
      "        20       -2380.2961          +0.4571\n",
      "        21       -2379.9350          +0.3611\n",
      "        22       -2379.6690          +0.2660\n",
      "        23       -2379.4766          +0.1924\n",
      "        24       -2379.3326          +0.1440\n",
      "        25       -2379.2187          +0.1139\n",
      "        26       -2379.1237          +0.0950\n",
      "        27       -2379.0406          +0.0831\n",
      "        28       -2378.9645          +0.0760\n",
      "        29       -2378.8918          +0.0727\n",
      "        30       -2378.8194          +0.0724\n",
      "        31       -2378.7446          +0.0748\n",
      "        32       -2378.6646          +0.0800\n",
      "        33       -2378.5767          +0.0880\n",
      "        34       -2378.4774          +0.0992\n",
      "        35       -2378.3630          +0.1144\n",
      "        36       -2378.2286          +0.1344\n",
      "        37       -2378.0683          +0.1603\n",
      "        38       -2377.8750          +0.1934\n",
      "        39       -2377.6402          +0.2347\n",
      "        40       -2377.3557          +0.2845\n",
      "        41       -2377.0149          +0.3408\n",
      "        42       -2376.6167          +0.3982\n",
      "        43       -2376.1684          +0.4483\n",
      "        44       -2375.6858          +0.4827\n",
      "        45       -2375.1880          +0.4978\n",
      "        46       -2374.6915          +0.4965\n",
      "        47       -2374.2056          +0.4859\n",
      "        48       -2373.7317          +0.4740\n",
      "        49       -2373.2642          +0.4675\n",
      "        50       -2372.7954          +0.4688\n",
      "        51       -2372.3236          +0.4718\n",
      "        52       -2371.8625          +0.4611\n",
      "        53       -2371.4419          +0.4206\n",
      "        54       -2371.0941          +0.3478\n",
      "        55       -2370.8353          +0.2588\n",
      "        56       -2370.6595          +0.1758\n",
      "        57       -2370.5466          +0.1129\n",
      "        58       -2370.4745          +0.0720\n",
      "        59       -2370.4265          +0.0480\n",
      "        60       -2370.3921          +0.0344\n",
      "        61       -2370.3654          +0.0268\n",
      "        62       -2370.3432          +0.0222\n",
      "        63       -2370.3240          +0.0192\n",
      "        64       -2370.3069          +0.0171\n",
      "        65       -2370.2915          +0.0154\n",
      "        66       -2370.2774          +0.0141\n",
      "        67       -2370.2643          +0.0130\n",
      "        68       -2370.2522          +0.0121\n",
      "        69       -2370.2408          +0.0114\n",
      "        70       -2370.2300          +0.0108\n",
      "        71       -2370.2196          +0.0104\n",
      "        72       -2370.2096          +0.0101"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "        73       -2370.1997          +0.0099\n"
     ]
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=4*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "Xcth = np.concatenate(trainset['duoc'])\n",
    "lengths = list([len(x) for x in trainset['duoc']])\n",
    "print(\"training class\", 'duoc')\n",
    "print(Xcth.shape, lengths, len(lengths))\n",
    "hmm.fit(Xcth, lengths=lengths)\n",
    "models['duoc'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'người' 4x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -4899.2129             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class nguoi\n",
      "(1892, 1) [20, 18, 23, 25, 25, 38, 20, 25, 27, 22, 23, 23, 20, 26, 23, 19, 28, 24, 25, 19, 22, 28, 19, 24, 28, 20, 20, 32, 20, 18, 20, 31, 22, 19, 24, 14, 22, 15, 13, 22, 19, 25, 18, 27, 20, 20, 24, 17, 22, 19, 22, 26, 20, 23, 35, 28, 22, 30, 25, 27, 26, 23, 31, 30, 21, 19, 18, 20, 22, 15, 26, 19, 22, 51, 37, 42, 29, 29, 19, 18] 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2       -3286.9278       +1612.2851\n",
      "         3       -2905.6138        +381.3141\n",
      "         4       -2683.3534        +222.2603\n",
      "         5       -2552.1228        +131.2306\n",
      "         6       -2498.4975         +53.6253\n",
      "         7       -2480.1086         +18.3889\n",
      "         8       -2471.5025          +8.6061\n",
      "         9       -2469.0258          +2.4767\n",
      "        10       -2467.4589          +1.5669\n",
      "        11       -2466.2027          +1.2562\n",
      "        12       -2465.0254          +1.1773\n",
      "        13       -2463.8099          +1.2155\n",
      "        14       -2462.4436          +1.3664\n",
      "        15       -2460.8176          +1.6260\n",
      "        16       -2458.8748          +1.9428\n",
      "        17       -2456.7023          +2.1724\n",
      "        18       -2454.5948          +2.1075\n",
      "        19       -2452.8868          +1.7080\n",
      "        20       -2451.6773          +1.2096\n",
      "        21       -2450.8438          +0.8334\n",
      "        22       -2450.2281          +0.6158\n",
      "        23       -2449.7209          +0.5072\n",
      "        24       -2449.2684          +0.4525\n",
      "        25       -2448.8641          +0.4043\n",
      "        26       -2448.5274          +0.3367\n",
      "        27       -2448.2694          +0.2579\n",
      "        28       -2448.0818          +0.1876\n",
      "        29       -2447.9486          +0.1333\n",
      "        30       -2447.8554          +0.0932\n",
      "        31       -2447.7911          +0.0642\n",
      "        32       -2447.7474          +0.0438\n",
      "        33       -2447.7177          +0.0297\n",
      "        34       -2447.6975          +0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        35       -2447.6836          +0.0139\n",
      "        36       -2447.6740          +0.0096\n"
     ]
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=4*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ], ])\n",
    "\n",
    "Xcth = np.concatenate(trainset['nguoi'])\n",
    "lengths = list([len(x) for x in trainset['nguoi']])\n",
    "print(\"training class\", 'nguoi')\n",
    "print(Xcth.shape, lengths, len(lengths))\n",
    "hmm.fit(Xcth, lengths=lengths)\n",
    "models['nguoi'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'trong' 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -6979.2600             +nan\n",
      "         2       -4976.1457       +2003.1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training class trong\n",
      "(2742, 1) [19, 23, 17, 30, 26, 38, 23, 21, 22, 24, 32, 32, 22, 29, 22, 18, 25, 26, 24, 21, 28, 21, 20, 20, 21, 19, 18, 30, 22, 22, 26, 23, 14, 12, 31, 19, 18, 21, 21, 23, 21, 24, 21, 21, 20, 18, 20, 20, 21, 20, 19, 24, 18, 24, 19, 31, 22, 16, 21, 22, 19, 20, 33, 28, 25, 24, 25, 23, 26, 19, 21, 38, 29, 34, 18, 22, 19, 23, 17, 19, 20, 23, 24, 21, 33, 20, 20, 25, 21, 21, 25, 25, 24, 19, 28, 30, 20, 22, 21, 19, 16, 22, 26, 17, 25, 18, 31, 20, 21, 28, 20, 20, 28, 21, 24, 21, 23, 29, 22, 22] 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3       -3912.6133       +1063.5324\n",
      "         4       -3525.4433        +387.1701\n",
      "         5       -3385.3957        +140.0476\n",
      "         6       -3327.8599         +57.5358\n",
      "         7       -3304.8240         +23.0358\n",
      "         8       -3293.5508         +11.2732\n",
      "         9       -3288.5326          +5.0182\n",
      "        10       -3285.9721          +2.5605\n",
      "        11       -3284.0368          +1.9354\n",
      "        12       -3282.1780          +1.8588\n",
      "        13       -3279.9690          +2.2090\n",
      "        14       -3276.7898          +3.1793\n",
      "        15       -3271.7769          +5.0128\n",
      "        16       -3264.8103          +6.9667\n",
      "        17       -3258.2669          +6.5434\n",
      "        18       -3254.3599          +3.9069\n",
      "        19       -3252.2052          +2.1548\n",
      "        20       -3250.3204          +1.8848\n",
      "        21       -3247.7972          +2.5232\n",
      "        22       -3240.5292          +7.2680\n",
      "        23       -3235.9796          +4.5496\n",
      "        24       -3234.7903          +1.1893\n",
      "        25       -3234.0843          +0.7060\n",
      "        26       -3233.5688          +0.5155\n",
      "        27       -3233.1611          +0.4077\n",
      "        28       -3232.8268          +0.3344\n",
      "        29       -3232.5462          +0.2805\n",
      "        30       -3232.3064          +0.2398\n",
      "        31       -3232.0967          +0.2097\n",
      "        32       -3231.9055          +0.1913\n",
      "        33       -3231.7094          +0.1961\n",
      "        34       -3231.4391          +0.2703\n",
      "        35       -3230.9284          +0.5107\n",
      "        36       -3230.1214          +0.8070\n",
      "        37       -3229.3783          +0.7431\n",
      "        38       -3228.8630          +0.5152\n",
      "        39       -3228.4500          +0.4130\n",
      "        40       -3228.0407          +0.4094\n",
      "        41       -3227.5815          +0.4592\n",
      "        42       -3227.0260          +0.5555\n",
      "        43       -3226.3165          +0.7096\n",
      "        44       -3225.3763          +0.9402\n",
      "        45       -3224.1072          +1.2691\n",
      "        46       -3222.3922          +1.7150\n",
      "        47       -3220.1124          +2.2799\n",
      "        48       -3217.1899          +2.9225\n",
      "        49       -3213.6636          +3.5263\n",
      "        50       -3209.7723          +3.8913\n",
      "        51       -3205.9683          +3.8040\n",
      "        52       -3202.7683          +3.2000\n",
      "        53       -3200.4849          +2.2834\n",
      "        54       -3199.0775          +1.4074\n",
      "        55       -3198.2758          +0.8017\n",
      "        56       -3197.8077          +0.4681\n",
      "        57       -3197.5069          +0.3007\n",
      "        58       -3197.2961          +0.2108\n",
      "        59       -3197.1419          +0.1542\n",
      "        60       -3197.0277          +0.1142\n",
      "        61       -3196.9433          +0.0844\n",
      "        62       -3196.8811          +0.0622\n",
      "        63       -3196.8354          +0.0457\n",
      "        64       -3196.8019          +0.0335\n",
      "        65       -3196.7773          +0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        66       -3196.7593          +0.0180\n",
      "        67       -3196.7461          +0.0132\n",
      "        68       -3196.7364          +0.0097\n"
     ]
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=3*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "Xvn = np.concatenate(trainset['trong'])\n",
    "lengths = list([len(x) for x in trainset['trong']])\n",
    "print(\"training class\", 'trong')\n",
    "print(Xvn.shape, lengths, len(lengths))\n",
    "hmm.fit(Xvn, lengths=lengths)\n",
    "models['trong'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'finalModel.sav'\n",
    "pickle.dump(models, open(fileName, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "cothe {'cothe': -435.072661289539, 'chungta': -1785.0329807245716, 'duoc': -738.4813183122659, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -100.63541899724476, 'chungta': -463.84271097190987, 'duoc': -536.0937736873146, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -199.57617216081914, 'chungta': -625.1678241372647, 'duoc': -236.93670755429324, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -220.86028015349706, 'chungta': -546.9045193596274, 'duoc': -3346.1700595492043, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -449.67027565708946, 'chungta': -583.424275495524, 'duoc': -1499.0191827648887, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -323.4672535784477, 'chungta': -1645.0431317790508, 'duoc': -1256.7225890030254, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -216.60788878647116, 'chungta': -1405.121490272712, 'duoc': -1937.1371436224401, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -493.8484347333702, 'chungta': -705.7156524863474, 'duoc': -1833.0818039480046, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -251.45609965405646, 'chungta': -690.6377565186259, 'duoc': -1940.4183482679784, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -187.45588304728417, 'chungta': -701.29096090262, 'duoc': -7772.164481136704, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -198.30575795681398, 'chungta': -795.2585602688881, 'duoc': -926.8247015217996, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -226.05301549441896, 'chungta': -737.6148806809513, 'duoc': -383.3815282561892, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -209.59772051703726, 'chungta': -1104.2919419296293, 'duoc': -1702.1234547110641, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -578.0056698579001, 'chungta': -1029.627677865722, 'duoc': -1726.557095238986, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -224.50181657663404, 'chungta': -637.2457421889847, 'duoc': -1439.5180173423305, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -169.97051286568757, 'chungta': -456.53038357315586, 'duoc': -7444.6403115328285, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -547.5148390585222, 'chungta': -747.9995451105353, 'duoc': -2295.565114064593, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -202.2181805633519, 'chungta': -526.9003082978747, 'duoc': -257.7698826342866, 'nguoi': -inf, 'trong': -510.5633345710067} predict: cothe\n",
      "cothe {'cothe': -188.50738437113804, 'chungta': -502.4954678680582, 'duoc': -297.02051312821624, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -678.8151845740423, 'chungta': -1534.7404528922777, 'duoc': -1653.16503092008, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -121.65402550220826, 'chungta': -1465.3481947342443, 'duoc': -3802.6603352867296, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -735.7211123785706, 'chungta': -1536.2821268977966, 'duoc': -1283.30511139535, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -374.69258913228714, 'chungta': -1765.2269772062903, 'duoc': -2017.0552534965334, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -133.96197430442928, 'chungta': -1111.6902106927073, 'duoc': -3790.7740187551353, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "cothe {'cothe': -194.22899698812458, 'chungta': -1153.9567446851663, 'duoc': -8833.12548866605, 'nguoi': -inf, 'trong': -inf} predict: cothe\n",
      "chungta {'cothe': -130.56752243287318, 'chungta': -42.75735419287445, 'duoc': -91.00093465014731, 'nguoi': -5198.3465415910305, 'trong': -664.0968562720611} predict: chungta\n",
      "chungta {'cothe': -449.51895504706, 'chungta': -35.79682401934499, 'duoc': -108.9928470535114, 'nguoi': -6735.273640367103, 'trong': -inf} predict: chungta\n",
      "chungta {'cothe': -323.46424421796814, 'chungta': -44.345349555695705, 'duoc': -95.67553981453125, 'nguoi': -3897.7095684704277, 'trong': -299.37934846159044} predict: chungta\n",
      "chungta {'cothe': -480.765244118505, 'chungta': -43.72777371144884, 'duoc': -102.35417027177263, 'nguoi': -3667.90931135889, 'trong': -inf} predict: chungta\n",
      "chungta {'cothe': -326.59452094173275, 'chungta': -34.10326985059814, 'duoc': -99.5282277516774, 'nguoi': -5806.350966092355, 'trong': -inf} predict: chungta\n",
      "chungta {'cothe': -124.89332109796747, 'chungta': -44.86857443631432, 'duoc': -98.48925064604992, 'nguoi': -4795.26798843671, 'trong': -664.6533811145126} predict: chungta\n",
      "chungta {'cothe': -523.2241820485792, 'chungta': -57.15957302166027, 'duoc': -969.0167004996462, 'nguoi': -inf, 'trong': -302.6482619723715} predict: chungta\n",
      "chungta {'cothe': -315.1746046297576, 'chungta': -47.43122004949593, 'duoc': -480.3873244172991, 'nguoi': -1560.0754714387685, 'trong': -inf} predict: chungta\n",
      "chungta {'cothe': -133.2639200542843, 'chungta': -52.893293426452566, 'duoc': -86.03843486799757, 'nguoi': -3894.676514142999, 'trong': -666.7512177135484} predict: chungta\n",
      "chungta {'cothe': -332.4623767103822, 'chungta': -41.94868475313877, 'duoc': -99.65489398472775, 'nguoi': -4433.62708420267, 'trong': -inf} predict: chungta\n",
      "chungta {'cothe': -118.76603175856013, 'chungta': -33.86616729933787, 'duoc': -424.01527481349865, 'nguoi': -6614.9809471362305, 'trong': -514.9856815015883} predict: chungta\n",
      "chungta {'cothe': -438.39584861396713, 'chungta': -44.33304801337606, 'duoc': -104.82103899540722, 'nguoi': -5584.046078810549, 'trong': -131.37101590911965} predict: chungta\n",
      "chungta {'cothe': -438.4220264471177, 'chungta': -39.89236989750908, 'duoc': -95.60783707420428, 'nguoi': -4141.1873102798, 'trong': -292.7095284012984} predict: chungta\n",
      "chungta {'cothe': -134.9407545265123, 'chungta': -38.47900947357711, 'duoc': -92.1774223223302, 'nguoi': -4734.764977174149, 'trong': -83.99643129372573} predict: chungta\n",
      "chungta {'cothe': -92.73802038038433, 'chungta': -26.974284844980186, 'duoc': -83.3946536211192, 'nguoi': -966.4541561182582, 'trong': -1111.570049747855} predict: chungta\n",
      "chungta {'cothe': -99.40081351750656, 'chungta': -35.56159461740119, 'duoc': -88.56591164786423, 'nguoi': -5757.4218216420595, 'trong': -200.2033223903766} predict: chungta\n",
      "chungta {'cothe': -313.6543276496297, 'chungta': -34.132139399285315, 'duoc': -91.9410636086755, 'nguoi': -914.0062134130642, 'trong': -81.70218535286345} predict: chungta\n",
      "chungta {'cothe': -143.22887847398852, 'chungta': -42.05537693675788, 'duoc': -81.53203636447257, 'nguoi': -3564.248696626242, 'trong': -384.28038793983535} predict: chungta\n",
      "chungta {'cothe': -354.7080165206492, 'chungta': -31.095444359664263, 'duoc': -89.53271869124134, 'nguoi': -1243.9734042471039, 'trong': -inf} predict: chungta\n",
      "chungta {'cothe': -305.27022886838995, 'chungta': -28.456480278099722, 'duoc': -89.06257050848079, 'nguoi': -1369.4657092946932, 'trong': -inf} predict: chungta\n",
      "duoc {'cothe': -157.70708686746156, 'chungta': -404.5738183074118, 'duoc': -63.40904720048862, 'nguoi': -67.16829988560644, 'trong': -506.126573932997} predict: duoc\n",
      "duoc {'cothe': -55.31102601641637, 'chungta': -191.5569013099303, 'duoc': -22.37028208924837, 'nguoi': -39.87262717036308, 'trong': -126.52517174990625} predict: duoc\n",
      "duoc {'cothe': -60.559883831251916, 'chungta': -215.4202810490423, 'duoc': -28.269629973947747, 'nguoi': -72.5628027798659, 'trong': -136.90381318275388} predict: duoc\n",
      "duoc {'cothe': -44.952392806993, 'chungta': -637.8843133997277, 'duoc': -38.5023603384559, 'nguoi': -57.426832000420745, 'trong': -484.3361222873891} predict: duoc\n",
      "duoc {'cothe': -78.82435765546563, 'chungta': -103.4061268729457, 'duoc': -60.918911069854964, 'nguoi': -inf, 'trong': -89.0062905371774} predict: duoc\n",
      "duoc {'cothe': -48.8975369827525, 'chungta': -711.4457497156902, 'duoc': -38.66893664227478, 'nguoi': -65.48834373476568, 'trong': -204.7576483193196} predict: duoc\n",
      "duoc {'cothe': -58.04978565885975, 'chungta': -807.0944880713719, 'duoc': -26.26523138882496, 'nguoi': -48.56529280125943, 'trong': -389.9276265595151} predict: duoc\n",
      "duoc {'cothe': -59.69820244996345, 'chungta': -731.4793793752378, 'duoc': -32.537110676483074, 'nguoi': -71.64232634368132, 'trong': -55.55344624451662} predict: duoc\n",
      "duoc {'cothe': -67.31873736073615, 'chungta': -714.8420627013751, 'duoc': -49.425536062885485, 'nguoi': -122.65874568348697, 'trong': -329.1621264126645} predict: duoc\n",
      "duoc {'cothe': -40.682234090679906, 'chungta': -700.8501567563187, 'duoc': -30.988449953283173, 'nguoi': -48.22776096082154, 'trong': -110.99615828235136} predict: duoc\n",
      "duoc {'cothe': -41.32842197123817, 'chungta': -207.70191731352537, 'duoc': -23.596506704177628, 'nguoi': -31.268419414682032, 'trong': -591.9943161474021} predict: duoc\n",
      "duoc {'cothe': -55.64893592006755, 'chungta': -58.60322044469304, 'duoc': -20.606041634889987, 'nguoi': -36.87914121338158, 'trong': -25.217612465011996} predict: duoc\n",
      "duoc {'cothe': -48.60231728252612, 'chungta': -37.56117812952651, 'duoc': -24.453384118320486, 'nguoi': -45.56111450190702, 'trong': -1409.4840400203504} predict: duoc\n",
      "duoc {'cothe': -52.39486888565852, 'chungta': -285.0629418548057, 'duoc': -23.195365001127144, 'nguoi': -66.36987397988278, 'trong': -305.006282580912} predict: duoc\n",
      "duoc {'cothe': -68.13549750730293, 'chungta': -149.11993632611322, 'duoc': -31.943903075254767, 'nguoi': -74.26528249627772, 'trong': -73.09096917455} predict: duoc\n",
      "duoc {'cothe': -54.04623336086323, 'chungta': -63.35935142703156, 'duoc': -31.147351310103918, 'nguoi': -69.5623285113932, 'trong': -47.772953889200295} predict: duoc\n",
      "duoc {'cothe': -70.57886571320563, 'chungta': -156.94607572775962, 'duoc': -25.399493156242958, 'nguoi': -71.21883852955278, 'trong': -73.22257081957333} predict: duoc\n",
      "duoc {'cothe': -32.27675183787802, 'chungta': -29.877913999810236, 'duoc': -20.059994449758346, 'nguoi': -29.355949700928456, 'trong': -23.342810548808284} predict: duoc\n",
      "duoc {'cothe': -40.19088836808352, 'chungta': -687.3094070161039, 'duoc': -36.82221869162399, 'nguoi': -56.69513210302866, 'trong': -384.9360846297426} predict: duoc\n",
      "duoc {'cothe': -21.71146037134895, 'chungta': -212.15004980672919, 'duoc': -22.334379004706943, 'nguoi': -14.578292864008505, 'trong': -167.1672514074603} predict: nguoi\n",
      "duoc {'cothe': -45.4243671287902, 'chungta': -192.16721527420725, 'duoc': -23.96007889163489, 'nguoi': -49.47631456864594, 'trong': -43.18357359378656} predict: duoc\n",
      "nguoi {'cothe': -33.252601392274684, 'chungta': -204.24349478164993, 'duoc': -32.61145905887764, 'nguoi': -20.344185852085307, 'trong': -94.6109958080151} predict: nguoi\n",
      "nguoi {'cothe': -49.17253275339116, 'chungta': -757.988740297708, 'duoc': -88.94068194781873, 'nguoi': -40.83964057206079, 'trong': -211.34299104274473} predict: nguoi\n",
      "nguoi {'cothe': -42.49692633047497, 'chungta': -130.41841331488345, 'duoc': -41.480154777093425, 'nguoi': -36.9763719965533, 'trong': -95.1651060186003} predict: nguoi\n",
      "nguoi {'cothe': -42.91864152570427, 'chungta': -311.6316969222015, 'duoc': -33.58958153600557, 'nguoi': -17.025246342662047, 'trong': -76.71345658933396} predict: nguoi\n",
      "nguoi {'cothe': -37.068453978716185, 'chungta': -322.89248084948383, 'duoc': -39.49877703028368, 'nguoi': -27.103052503358615, 'trong': -60.481127886490825} predict: nguoi\n",
      "nguoi {'cothe': -32.44376219022717, 'chungta': -625.9873387324523, 'duoc': -30.395942378673613, 'nguoi': -27.02657119423673, 'trong': -173.92903888919102} predict: nguoi\n",
      "nguoi {'cothe': -51.1126440818886, 'chungta': -290.18155474910196, 'duoc': -54.487940571816104, 'nguoi': -31.160515019748633, 'trong': -163.80448156627958} predict: nguoi\n",
      "nguoi {'cothe': -52.827631322797586, 'chungta': -831.1051521217795, 'duoc': -63.48915142612701, 'nguoi': -33.431625045137785, 'trong': -167.70740823158724} predict: nguoi\n",
      "nguoi {'cothe': -43.1522000210396, 'chungta': -193.51632319822636, 'duoc': -84.22944191579441, 'nguoi': -33.19327228339806, 'trong': -433.55485583431704} predict: nguoi\n",
      "nguoi {'cothe': -35.37861615389751, 'chungta': -178.5840778610344, 'duoc': -22.686745731097975, 'nguoi': -20.390457492743526, 'trong': -95.11636852169276} predict: nguoi\n",
      "nguoi {'cothe': -49.25283253562707, 'chungta': -372.3292591208974, 'duoc': -47.37445755809702, 'nguoi': -26.804458833620725, 'trong': -91.62409334920032} predict: nguoi\n",
      "nguoi {'cothe': -55.37290473911638, 'chungta': -216.44809826934957, 'duoc': -39.70646552233482, 'nguoi': -24.78149940555751, 'trong': -169.88496963687118} predict: nguoi\n",
      "nguoi {'cothe': -36.383915574459564, 'chungta': -145.30465503423557, 'duoc': -26.591921701072515, 'nguoi': -21.458360500556747, 'trong': -66.01692734813759} predict: nguoi\n",
      "nguoi {'cothe': -35.237342374068405, 'chungta': -99.54638146845309, 'duoc': -30.697569180214686, 'nguoi': -32.357057850558824, 'trong': -154.11782847522434} predict: duoc\n",
      "nguoi {'cothe': -28.37348543063218, 'chungta': -174.17843907664667, 'duoc': -16.746390076001774, 'nguoi': -15.54445934887426, 'trong': -87.75967796287915} predict: nguoi\n",
      "nguoi {'cothe': -30.098310079325103, 'chungta': -254.22390323626092, 'duoc': -44.55322139507367, 'nguoi': -24.536341164391885, 'trong': -63.57226612865237} predict: nguoi\n",
      "nguoi {'cothe': -32.1565792200117, 'chungta': -455.7576559009944, 'duoc': -46.65164021162488, 'nguoi': -16.548498885328385, 'trong': -134.50718578030538} predict: nguoi\n",
      "nguoi {'cothe': -36.758037726905314, 'chungta': -143.03295447877153, 'duoc': -36.20197455136796, 'nguoi': -20.785051410807206, 'trong': -64.0271820824917} predict: nguoi\n",
      "nguoi {'cothe': -43.316604997307294, 'chungta': -310.9473898790093, 'duoc': -41.585805870919465, 'nguoi': -19.951219196660098, 'trong': -150.0669426554894} predict: nguoi\n",
      "nguoi {'cothe': -39.66684884561454, 'chungta': -443.67170339331796, 'duoc': -28.25825467156376, 'nguoi': -24.81262048549301, 'trong': -361.80915165707813} predict: nguoi\n",
      "trong {'cothe': -118.00564714831955, 'chungta': -40.33972308850789, 'duoc': -56.49293301718416, 'nguoi': -1809.9341971149186, 'trong': -26.387477765844277} predict: trong\n",
      "trong {'cothe': -134.15532145999381, 'chungta': -218.71396850958143, 'duoc': -93.59372705203853, 'nguoi': -1969.6402499797364, 'trong': -61.80085713756551} predict: trong\n",
      "trong {'cothe': -72.07678090645807, 'chungta': -44.96116162003873, 'duoc': -42.63104236722016, 'nguoi': -1860.678267496355, 'trong': -21.451653832198502} predict: trong\n",
      "trong {'cothe': -90.92232828139686, 'chungta': -52.422786866933706, 'duoc': -53.33794065032583, 'nguoi': -1609.5390654730502, 'trong': -29.18562735869093} predict: trong\n",
      "trong {'cothe': -72.47690131070803, 'chungta': -31.124707280023816, 'duoc': -47.15904199686972, 'nguoi': -1481.9030950145498, 'trong': -23.98191706310032} predict: trong\n",
      "trong {'cothe': -111.29379323777928, 'chungta': -39.181433211267674, 'duoc': -58.27219289666353, 'nguoi': -1843.4315759795213, 'trong': -25.739988324970533} predict: trong\n",
      "trong {'cothe': -80.81501525371978, 'chungta': -33.03218226659206, 'duoc': -51.330970999549194, 'nguoi': -1600.9095122917063, 'trong': -20.36957308683793} predict: trong\n",
      "trong {'cothe': -76.40989958069291, 'chungta': -42.53982802699278, 'duoc': -67.06117531535389, 'nguoi': -1788.8898061945297, 'trong': -26.699320932085307} predict: trong\n",
      "trong {'cothe': -78.37470760522987, 'chungta': -808.1505224752981, 'duoc': -49.531842276519896, 'nguoi': -2049.0779106064533, 'trong': -32.136353199144644} predict: trong\n",
      "trong {'cothe': -83.38389678726595, 'chungta': -45.24692182782639, 'duoc': -44.06793397077241, 'nguoi': -2063.1707487091435, 'trong': -27.270415895022367} predict: trong\n",
      "trong {'cothe': -73.96575631157596, 'chungta': -45.09206093348479, 'duoc': -46.01328867472851, 'nguoi': -2118.8260855817457, 'trong': -27.25963276174091} predict: trong\n",
      "trong {'cothe': -112.53749971304796, 'chungta': -37.18475357963115, 'duoc': -63.16149166646656, 'nguoi': -2174.72328561614, 'trong': -29.21645579405147} predict: trong\n",
      "trong {'cothe': -84.39940717141361, 'chungta': -28.05781947202116, 'duoc': -74.36083813586151, 'nguoi': -1922.9374609528836, 'trong': -24.829072103280318} predict: trong\n",
      "trong {'cothe': -57.66119277816159, 'chungta': -47.343482565837455, 'duoc': -36.34005429240799, 'nguoi': -1716.07208937668, 'trong': -35.18131373894905} predict: trong\n",
      "trong {'cothe': -59.49992611602316, 'chungta': -33.384829420114336, 'duoc': -43.6758095397142, 'nguoi': -1931.1145730926885, 'trong': -25.521743265296735} predict: trong\n",
      "trong {'cothe': -82.95285890567912, 'chungta': -960.4056672854236, 'duoc': -48.30188999355012, 'nguoi': -1033.0778311619006, 'trong': -788.8260348284117} predict: duoc\n",
      "trong {'cothe': -78.71936736743763, 'chungta': -645.1989488426932, 'duoc': -54.60786073781957, 'nguoi': -562.8638152456899, 'trong': -35.671555041469944} predict: trong\n",
      "trong {'cothe': -94.88533802896455, 'chungta': -39.24238459404516, 'duoc': -84.44722426365314, 'nguoi': -1327.5887558764007, 'trong': -35.317369387175766} predict: trong\n",
      "trong {'cothe': -69.0122571920481, 'chungta': -33.40676599082148, 'duoc': -44.5269330617447, 'nguoi': -590.443539231594, 'trong': -73.50813380456022} predict: chungta\n",
      "trong {'cothe': -104.61657625443246, 'chungta': -61.47350493919139, 'duoc': -61.33214194284115, 'nguoi': -inf, 'trong': -34.641236384733645} predict: trong\n",
      "trong {'cothe': -69.89950962244785, 'chungta': -106.08302994290226, 'duoc': -44.1417837886165, 'nguoi': -947.639324304417, 'trong': -33.108304645609124} predict: trong\n",
      "trong {'cothe': -62.94015220618091, 'chungta': -44.58682551540145, 'duoc': -51.68264549444751, 'nguoi': -61.51045144624859, 'trong': -32.80739406294995} predict: trong\n",
      "trong {'cothe': -60.17835294600553, 'chungta': -60.098834759581024, 'duoc': -67.72395394799166, 'nguoi': -68.13746529851115, 'trong': -50.643945339884915} predict: trong\n",
      "trong {'cothe': -48.839343111456856, 'chungta': -125.71903695249345, 'duoc': -42.72659088709996, 'nguoi': -49.90613336490893, 'trong': -47.12931930469656} predict: duoc\n",
      "trong {'cothe': -54.23797667553143, 'chungta': -193.1334576556594, 'duoc': -34.05643850584756, 'nguoi': -49.78075842177307, 'trong': -442.03208980773024} predict: duoc\n",
      "trong {'cothe': -83.1361091688227, 'chungta': -142.63369485610886, 'duoc': -41.44131812194139, 'nguoi': -1424.9896920169128, 'trong': -30.755050706559388} predict: trong\n",
      "trong {'cothe': -70.53113599877993, 'chungta': -228.32762434833307, 'duoc': -57.717050249843155, 'nguoi': -81.97815526475658, 'trong': -52.96003048361451} predict: trong\n",
      "trong {'cothe': -132.79683541848226, 'chungta': -176.65447473036411, 'duoc': -82.45218300726954, 'nguoi': -inf, 'trong': -142.69256086646317} predict: duoc\n",
      "trong {'cothe': -71.46870937551202, 'chungta': -122.06914147005388, 'duoc': -44.22962582227322, 'nguoi': -76.30515737233823, 'trong': -28.088383849706155} predict: trong\n",
      "trong {'cothe': -75.2119050600829, 'chungta': -134.42230765498985, 'duoc': -50.34959441374061, 'nguoi': -83.36668863351801, 'trong': -33.305185014981916} predict: trong\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "n_correct = {'cothe': 0, 'chungta': 0, 'duoc': 0, 'nguoi': 0,'trong': 0}\n",
    "y_true = []\n",
    "y_predict = []\n",
    "labels = ['cothe', 'chungta', 'duoc', 'nguoi', 'trong']\n",
    "for true_cname in class_names:\n",
    "    for O in testset[true_cname]:\n",
    "        score = {cname: model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "        if (true_cname == max(score, key=score.get)): n_correct[true_cname] += 1\n",
    "        y_true.append(true_cname)\n",
    "        y_predict.append(max(score, key = score.get))\n",
    "        print(true_cname, score, 'predict:', max(score, key=score.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: cothe 1.0\n",
      "Accuracy: chungta 1.0\n",
      "Accuracy: duoc 0.9523809523809523\n",
      "Accuracy: nguoi 0.95\n",
      "Accuracy: trong 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "for cname in class_names:\n",
    "    print('Accuracy:', cname, n_correct[cname]/n_test[cname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracy: 0.9396551724137931\n"
     ]
    }
   ],
   "source": [
    "print('All Accuracy:', sum(n_correct.values())/sum(n_test.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass labels=['cothe', 'chungta', 'duoc', 'nguoi', 'trong'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotCM(y_true, y_predict, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cothe': 25, 'chungta': 20, 'duoc': 21, 'nguoi': 20, 'trong': 30}\n"
     ]
    }
   ],
   "source": [
    "print(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test âm thu từ micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing testDataSet\n",
      "chungta {'cothe': -156.05843252483922, 'chungta': -188.5098175158359, 'duoc': -119.43134111118295, 'nguoi': -502.96670427329104, 'trong': -584.0690807967635} predict: duoc\n",
      "chungta {'cothe': -149.21120866066664, 'chungta': -82.85926081917718, 'duoc': -128.5935374196593, 'nguoi': -1777.8142097158764, 'trong': -690.2531693667312} predict: chungta\n",
      "chungta {'cothe': -187.01327953023807, 'chungta': -79.50356662758963, 'duoc': -109.74566332892684, 'nguoi': -2757.1668632007472, 'trong': -273.12354659813496} predict: chungta\n",
      "chungta {'cothe': -128.15320391944593, 'chungta': -77.24194294343371, 'duoc': -96.91999798388639, 'nguoi': -106.1780388231588, 'trong': -141.46423459648554} predict: chungta\n",
      "chungta {'cothe': -267.4595379836476, 'chungta': -72.39228924179778, 'duoc': -120.88446270240814, 'nguoi': -3296.2911740203035, 'trong': -1388.1889115562979} predict: chungta\n",
      "duoc {'cothe': -35.63745039598357, 'chungta': -27.746901757081893, 'duoc': -19.24092074481348, 'nguoi': -30.55467626922456, 'trong': -28.463758318833285} predict: duoc\n",
      "duoc {'cothe': -49.751144834802275, 'chungta': -113.35106723560791, 'duoc': -20.217160409318016, 'nguoi': -35.12720016278564, 'trong': -36.416273085633094} predict: duoc\n",
      "duoc {'cothe': -35.21672572454145, 'chungta': -34.61023670330419, 'duoc': -22.4465893464337, 'nguoi': -40.75966635671066, 'trong': -82.24012873935091} predict: duoc\n",
      "duoc {'cothe': -51.19507704790871, 'chungta': -178.6799717599948, 'duoc': -30.765285854608805, 'nguoi': -53.33190786764127, 'trong': -114.894967615374} predict: duoc\n",
      "duoc {'cothe': -38.77056670419798, 'chungta': -112.17872798780206, 'duoc': -23.85057797756331, 'nguoi': -28.788897988312485, 'trong': -46.51744484238009} predict: duoc\n",
      "trong {'cothe': -94.24129467331052, 'chungta': -86.73428670200896, 'duoc': -83.94732374583805, 'nguoi': -3078.7994298151834, 'trong': -49.15099967141642} predict: trong\n",
      "trong {'cothe': -73.00444541578139, 'chungta': -64.95659965569209, 'duoc': -43.98165823607854, 'nguoi': -inf, 'trong': -32.65873352288319} predict: trong\n",
      "trong {'cothe': -80.89911552714004, 'chungta': -70.9324057976308, 'duoc': -62.21157602278239, 'nguoi': -inf, 'trong': -43.7332674388727} predict: trong\n",
      "trong {'cothe': -89.38710107002761, 'chungta': -65.37287329494312, 'duoc': -55.63427284514878, 'nguoi': -2468.9890168340016, 'trong': -32.132295540760765} predict: trong\n",
      "trong {'cothe': -83.6511089149715, 'chungta': -133.28244573597811, 'duoc': -50.615210485720766, 'nguoi': -inf, 'trong': -173.9057076080417} predict: duoc\n",
      "nguoi {'cothe': -58.065163853173864, 'chungta': -130.0296152915614, 'duoc': -67.73766316132695, 'nguoi': -29.48987903324123, 'trong': -269.49211374726855} predict: nguoi\n",
      "nguoi {'cothe': -88.15739312402236, 'chungta': -509.16607262663615, 'duoc': -55.485509173657654, 'nguoi': -60.06049554320251, 'trong': -909.317426057272} predict: duoc\n",
      "nguoi {'cothe': -68.20337761940625, 'chungta': -285.3229397796043, 'duoc': -67.05452221308511, 'nguoi': -43.17483443574385, 'trong': -566.8023057229146} predict: nguoi\n",
      "nguoi {'cothe': -55.06836900689261, 'chungta': -373.18782115929304, 'duoc': -55.03106869608557, 'nguoi': -30.500840818073193, 'trong': -182.15510831310098} predict: nguoi\n",
      "nguoi {'cothe': -60.24681187362067, 'chungta': -209.0176627326468, 'duoc': -48.37159507247992, 'nguoi': -29.204689884920825, 'trong': -627.2937210752294} predict: nguoi\n",
      "cothe {'cothe': -58.68812905501246, 'chungta': -202.08177628327468, 'duoc': -108.32864497034286, 'nguoi': -82.08724045840425, 'trong': -490.9435015619095} predict: cothe\n",
      "cothe {'cothe': -88.90295565124649, 'chungta': -375.8622105195457, 'duoc': -123.68313590553379, 'nguoi': -inf, 'trong': -1627.051316693111} predict: cothe\n",
      "cothe {'cothe': -65.96478029891277, 'chungta': -182.42134943654213, 'duoc': -107.31638135602296, 'nguoi': -139.00639906964125, 'trong': -264.2966344364575} predict: cothe\n",
      "cothe {'cothe': -73.62895473114993, 'chungta': -83.58035381232582, 'duoc': -128.75773071254937, 'nguoi': -inf, 'trong': -1426.0264069610575} predict: cothe\n",
      "cothe {'cothe': -79.33141423942807, 'chungta': -111.89994597241548, 'duoc': -126.35781321248305, 'nguoi': -inf, 'trong': -1648.107976294371} predict: cothe\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing testDataSet\")\n",
    "n_correct = {'cothe': 0, 'chungta': 0, 'duoc': 0, 'nguoi': 0,'trong': 0}\n",
    "y_testTrue = []\n",
    "y_testPredict = []\n",
    "labels = ['cothe', 'chungta', 'duoc', 'nguoi', 'trong']\n",
    "for true_cname in testClass_names:\n",
    "    for O in testDataSet[true_cname]:\n",
    "        score = {cname: model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "        if (true_cname == max(score, key=score.get)): n_correct[true_cname] += 1\n",
    "        y_testTrue.append(true_cname)\n",
    "        y_testPredict.append(max(score, key = score.get))\n",
    "        print(true_cname, score, 'predict:', max(score, key=score.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.around(models['trong'].transmat_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: chungta 0.8\n",
      "Accuracy: duoc 1.0\n",
      "Accuracy: trong 0.8\n",
      "Accuracy: nguoi 0.8\n",
      "Accuracy: cothe 1.0\n",
      "All Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "for cname in testClass_names:\n",
    "    print('Accuracy:', cname, n_correct[cname]/n_testDataSet[cname])\n",
    "print('All Accuracy:', sum(n_correct.values())/sum(n_testDataSet.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass labels=['cothe', 'chungta', 'duoc', 'nguoi', 'trong'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotCM(y_testTrue, y_testPredict, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
