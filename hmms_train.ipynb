{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MFCC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lấy mfcc của tất cả các file trong dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy mfcc của tất cả các file wav trong wav\n",
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(X, n_clusters=14):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Load cothe dataset\nLoad da dataset\nLoad duoc dataset\nLoad nguoi dataset\nLoad trong dataset\n"
    }
   ],
   "source": [
    "class_names = ['cothe', 'da', 'duoc', 'nguoi','trong']\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join('data',cname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "124\n99\n100\n100\n100\n"
    }
   ],
   "source": [
    "print(len(dataset['cothe']))\n",
    "print(len(dataset['da']))\n",
    "print(len(dataset['duoc']))\n",
    "print(len(dataset['nguoi']))\n",
    "print(len(dataset['trong']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "111\n89\n90\n90\n90\n"
    }
   ],
   "source": [
    "trainset = {}\n",
    "testset = {}\n",
    "n_test = {'cothe': 0, 'da': 0, 'duoc': 0, 'nguoi': 0,'trong': 0}\n",
    "for cname in class_names:\n",
    "    n = len(dataset[cname])\n",
    "    n_train = math.floor(n*0.9)\n",
    "    trainset[cname] = dataset[cname][:n_train]\n",
    "    testset[cname] = dataset[cname][n_train:]\n",
    "    n_test[cname] += len(testset[cname])\n",
    "    \n",
    "print(len(trainset['cothe']))\n",
    "print(len(trainset['da']))\n",
    "print(len(trainset['duoc']))\n",
    "print(len(trainset['nguoi']))\n",
    "print(len(trainset['trong']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit kmeans trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "vectors (14283, 36)\ncenters (14, 36)\ncenters (14, 36)\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n       n_clusters=14, n_init=50, n_jobs=None, precompute_distances='auto',\n       random_state=0, tol=0.0001, verbose=0)\n"
    }
   ],
   "source": [
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in trainset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "print(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cname in class_names:\n",
    "    trainset[cname] = list([kmeans.predict(v).reshape(-1, 1) for v in trainset[cname]])\n",
    "    testset[cname] = list([kmeans.predict(v).reshape(-1, 1) for v in testset[cname]])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'có thể' 5x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training class cothe\n(6331, 1) [34, 31, 56, 39, 44, 40, 46, 35, 45, 47, 37, 56, 36, 31, 39, 35, 42, 30, 30, 37, 36, 39, 26, 34, 47, 36, 41, 34, 26, 30, 25, 27, 16, 39, 27, 52, 25, 27, 20, 22, 36, 53, 44, 44, 28, 57, 53, 36, 37, 30, 34, 38, 51, 43, 40, 47, 38, 44, 102, 44, 52, 56, 35, 37, 39, 25, 41, 52, 43, 33, 49, 59, 35, 42, 40, 37, 40, 35, 36, 28, 45, 44, 23, 30, 48, 35, 32, 35, 35, 26, 36, 43, 45, 62, 165, 163, 179, 165, 158, 179, 144, 154, 142, 141, 153, 162, 146, 163, 148, 144, 154] 111\n         1      -16057.5100             +nan\n         2      -11647.4536       +4410.0565\n         3      -10307.0475       +1340.4061\n         4       -9737.5345        +569.5130\n         5       -9547.1800        +190.3544\n         6       -9444.6261        +102.5539\n         7       -9411.3628         +33.2633\n         8       -9394.9771         +16.3858\n         9       -9381.3271         +13.6500\n        10       -9365.3570         +15.9701\n        11       -9346.4665         +18.8905\n        12       -9327.6596         +18.8069\n        13       -9300.2578         +27.4018\n        14       -9269.6398         +30.6180\n        15       -9246.1832         +23.4566\n        16       -9224.2927         +21.8904\n        17       -9198.1007         +26.1921\n        18       -9183.5148         +14.5858\n        19       -9175.1927          +8.3221\n        20       -9170.2849          +4.9078\n        21       -9167.8291          +2.4559\n        22       -9165.8337          +1.9953\n        23       -9163.0987          +2.7350\n        24       -9160.6701          +2.4286\n        25       -9158.0129          +2.6572\n        26       -9152.1614          +5.8515\n        27       -9137.8774         +14.2840\n        28       -9128.3451          +9.5323\n        29       -9125.6910          +2.6541\n        30       -9123.9809          +1.7101\n        31       -9119.1309          +4.8499\n        32       -9116.7644          +2.3665\n        33       -9100.3780         +16.3864\n        34       -8990.2793        +110.0988\n        35       -8951.1040         +39.1752\n        36       -8948.8331          +2.2709\n        37       -8945.6973          +3.1358\n        38       -8934.5607         +11.1366\n        39       -8922.8838         +11.6770\n        40       -8903.7988         +19.0850\n        41       -8896.6577          +7.1410\n        42       -8895.7420          +0.9158\n        43       -8895.5145          +0.2275\n        44       -8895.3865          +0.1280\n        45       -8895.1950          +0.1915\n        46       -8894.8650          +0.3300\n        47       -8894.4739          +0.3911\n        48       -8894.1961          +0.2778\n        49       -8894.0166          +0.1796\n        50       -8893.8921          +0.1245\n        51       -8893.8040          +0.0882\n        52       -8893.4654          +0.3386\n        53       -8891.4811          +1.9843\n        54       -8890.2961          +1.1850\n        55       -8890.2106          +0.0855\n        56       -8890.2003          +0.0103\nTraining done\n        57       -8890.1941          +0.0061\n"
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=4*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "\n",
    "Xbn = np.concatenate(trainset['cothe'])\n",
    "lengths = list([len(x) for x in trainset['cothe']])\n",
    "print(\"training class\", 'cothe')\n",
    "print(Xbn.shape, lengths, len(lengths))\n",
    "hmm.fit(Xbn, lengths=lengths)\n",
    "models['cothe'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'đã' 2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training class da\n(1684, 1) [15, 14, 16, 14, 16, 26, 12, 13, 17, 13, 23, 13, 16, 14, 12, 19, 20, 24, 20, 20, 24, 20, 18, 26, 26, 22, 21, 21, 15, 20, 35, 25, 16, 18, 16, 26, 20, 22, 22, 30, 20, 21, 25, 24, 20, 21, 22, 22, 19, 21, 15, 20, 14, 16, 15, 21, 15, 16, 19, 12, 18, 18, 15, 24, 24, 22, 17, 15, 18, 19, 18, 15, 15, 18, 15, 11, 18, 27, 13, 13, 14, 14, 19, 22, 18, 21, 36, 15, 14] 89\n         1       -4381.2288             +nan\n         2       -3554.7080        +826.5208\n         3       -3322.0183        +232.6897\n         4       -3156.3250        +165.6932\n         5       -3050.6600        +105.6651\n         6       -2990.4260         +60.2340\n         7       -2952.1655         +38.2605\n         8       -2927.0470         +25.1184\n         9       -2910.7456         +16.3014\n        10       -2898.2168         +12.5288\n        11       -2889.0407          +9.1761\n        12       -2882.7763          +6.2644\n        13       -2876.3763          +6.4000\n        14       -2865.0941         +11.2822\n        15       -2851.3266         +13.7674\n        16       -2830.5805         +20.7461\n        17       -2825.4735          +5.1070\n        18       -2824.2696          +1.2039\n        19       -2823.5971          +0.6725\n        20       -2822.9456          +0.6515\n        21       -2820.4984          +2.4472\n        22       -2816.7197          +3.7787\n        23       -2815.6643          +1.0553\n        24       -2815.3169          +0.3474\n        25       -2815.1557          +0.1613\n        26       -2815.0576          +0.0980\n        27       -2814.9839          +0.0737\n        28       -2814.9202          +0.0637\n        29       -2814.8602          +0.0600\n        30       -2814.8004          +0.0597\n        31       -2814.7384          +0.0620\n        32       -2814.6715          +0.0669\n        33       -2814.5967          +0.0748\n        34       -2814.5102          +0.0866\n        35       -2814.4066          +0.1036\n        36       -2814.2792          +0.1274\n        37       -2814.1195          +0.1597\n        38       -2813.9189          +0.2006\n        39       -2813.6745          +0.2444\n        40       -2813.3995          +0.2750\n        41       -2813.1293          +0.2702\n        42       -2812.9041          +0.2252\n        43       -2812.7404          +0.1637\n        44       -2812.6286          +0.1118\n        45       -2812.5516          +0.0771\n        46       -2812.4958          +0.0557\n        47       -2812.4534          +0.0425\n        48       -2812.4196          +0.0338\n        49       -2812.3918          +0.0277\n        50       -2812.3685          +0.0233\n        51       -2812.3485          +0.0200\n        52       -2812.3309          +0.0176\n        53       -2812.3149          +0.0160\n        54       -2812.2998          +0.0151\n        55       -2812.2850          +0.0148\n        56       -2812.2696          +0.0154\n        57       -2812.2528          +0.0168\n        58       -2812.2337          +0.0191\n        59       -2812.2113          +0.0224\n        60       -2812.1847          +0.0267\n        61       -2812.1528          +0.0319\n        62       -2812.1152          +0.0376\n        63       -2812.0717          +0.0435\n        64       -2812.0231          +0.0487\n        65       -2811.9706          +0.0525\n        66       -2811.9163          +0.0543\n        67       -2811.8625          +0.0539\n        68       -2811.8109          +0.0515\n        69       -2811.7632          +0.0477\n        70       -2811.7198          +0.0434\n        71       -2811.6807          +0.0392\n        72       -2811.6448          +0.0358\n        73       -2811.6109          +0.0340\n        74       -2811.5769          +0.0340\n        75       -2811.5408          +0.0361\n        76       -2811.5009          +0.0399\n        77       -2811.4562          +0.0447\n        78       -2811.4074          +0.0488\n        79       -2811.3567          +0.0507\n        80       -2811.3072          +0.0495\n        81       -2811.2618          +0.0454\n        82       -2811.2223          +0.0394\n        83       -2811.1895          +0.0328\nTraining done\n        84       -2811.1631          +0.0264\n        85       -2811.1423          +0.0208\n        86       -2811.1262          +0.0161\n        87       -2811.1138          +0.0124\n        88       -2811.1042          +0.0096\n"
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=2*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0 ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],])\n",
    "\n",
    "Xct = np.concatenate(trainset['da'])\n",
    "lengths = list([len(x) for x in trainset['da']])\n",
    "print(\"training class\", 'da')\n",
    "print(Xct.shape, lengths, len(lengths))\n",
    "hmm.fit(Xct, lengths=lengths)\n",
    "models['da'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'được' 4x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training class duoc\n(2034, 1) [22, 21, 27, 23, 30, 15, 18, 21, 30, 19, 20, 21, 30, 22, 14, 17, 23, 23, 19, 21, 18, 18, 20, 38, 21, 22, 35, 29, 18, 19, 22, 42, 22, 20, 24, 22, 21, 22, 22, 44, 29, 18, 14, 20, 24, 22, 19, 41, 24, 20, 18, 16, 20, 18, 21, 22, 30, 17, 21, 19, 16, 19, 18, 19, 16, 20, 14, 17, 16, 32, 26, 28, 24, 25, 25, 29, 21, 15, 17, 31, 22, 26, 27, 31, 24, 19, 24, 31, 18, 16] 90\n         1       -5260.9008             +nan\n         2       -3794.3014       +1466.5994\n         3       -3415.6769        +378.6245\n         4       -3189.2896        +226.3872\n         5       -3046.4704        +142.8193\n         6       -2967.0005         +79.4699\n         7       -2925.3974         +41.6031\n         8       -2899.7747         +25.6227\n         9       -2882.1036         +17.6710\n        10       -2869.3647         +12.7389\n        11       -2858.9502         +10.4145\n        12       -2849.1079          +9.8422\n        13       -2841.0696          +8.0383\n        14       -2835.2965          +5.7732\n        15       -2830.1072          +5.1893\n        16       -2824.8935          +5.2137\n        17       -2819.5282          +5.3653\n        18       -2814.0943          +5.4339\n        19       -2809.0867          +5.0076\n        20       -2805.2229          +3.8638\n        21       -2802.7268          +2.4961\n        22       -2801.2567          +1.4701\n        23       -2800.3617          +0.8950\n        24       -2799.7470          +0.6147\n        25       -2799.2666          +0.4804\n        26       -2798.8457          +0.4209\n        27       -2798.4277          +0.4181\n        28       -2797.9542          +0.4735\n        29       -2797.3871          +0.5671\n        30       -2796.7785          +0.6086\n        31       -2796.2417          +0.5368\n        32       -2795.7719          +0.4698\n        33       -2795.2546          +0.5173\n        34       -2794.5726          +0.6820\n        35       -2793.6604          +0.9122\n        36       -2792.5666          +1.0938\n        37       -2791.4594          +1.1072\n        38       -2790.5100          +0.9494\n        39       -2789.7916          +0.7183\n        40       -2789.2898          +0.5018\n        41       -2788.9536          +0.3362\n        42       -2788.7301          +0.2236\n        43       -2788.5762          +0.1538\n        44       -2788.4575          +0.1188\n        45       -2788.3180          +0.1394\n        46       -2787.9392          +0.3789\n        47       -2786.8775          +1.0617\n        48       -2785.7753          +1.1021\n        49       -2785.2476          +0.5277\n        50       -2784.9630          +0.2846\n        51       -2784.7622          +0.2007\n        52       -2784.5934          +0.1688\n        53       -2784.4361          +0.1573\n        54       -2784.2811          +0.1550\n        55       -2784.1229          +0.1582\n        56       -2783.9540          +0.1689\n        57       -2783.7569          +0.1970\n        58       -2783.4941          +0.2629\n        59       -2783.1028          +0.3912\n        60       -2782.5204          +0.5825\n        61       -2781.7652          +0.7552\n        62       -2781.0522          +0.7130\n        63       -2780.6396          +0.4127\n        64       -2780.4813          +0.1583\n        65       -2780.4262          +0.0551\n        66       -2780.4043          +0.0218\nTraining done\n        67       -2780.3938          +0.0105\n        68       -2780.3877          +0.0062\n"
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=4*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "Xcth = np.concatenate(trainset['duoc'])\n",
    "lengths = list([len(x) for x in trainset['duoc']])\n",
    "print(\"training class\", 'duoc')\n",
    "print(Xcth.shape, lengths, len(lengths))\n",
    "hmm.fit(Xcth, lengths=lengths)\n",
    "models['duoc'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'người' 4x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training class nguoi\n(2118, 1) [20, 18, 23, 25, 25, 38, 20, 25, 27, 22, 23, 23, 20, 26, 23, 19, 28, 24, 25, 19, 22, 28, 19, 24, 28, 20, 20, 32, 20, 18, 20, 31, 22, 19, 24, 14, 22, 15, 13, 22, 19, 25, 18, 27, 20, 20, 24, 17, 22, 19, 22, 26, 20, 23, 35, 28, 22, 30, 25, 27, 26, 23, 31, 30, 21, 19, 18, 20, 22, 15, 26, 19, 22, 51, 37, 42, 29, 29, 19, 18, 21, 27, 23, 23, 17, 17, 23, 26, 31, 18] 90\n         1       -5527.4822             +nan\n         2       -3591.6507       +1935.8316\n         3       -3103.4051        +488.2456\n         4       -2844.3123        +259.0928\n         5       -2739.3397        +104.9726\n         6       -2695.5682         +43.7715\n         7       -2673.8337         +21.7345\n         8       -2660.9006         +12.9331\n         9       -2651.7837          +9.1168\n        10       -2644.2367          +7.5471\n        11       -2636.2948          +7.9419\n        12       -2625.8593         +10.4355\n        13       -2611.8909         +13.9684\n        14       -2597.4503         +14.4406\n        15       -2585.4286         +12.0217\n        16       -2574.8360         +10.5927\n        17       -2566.5192          +8.3168\n        18       -2558.4329          +8.0862\n        19       -2551.9920          +6.4409\n        20       -2548.9983          +2.9937\n        21       -2547.3178          +1.6806\n        22       -2545.9813          +1.3364\n        23       -2544.4767          +1.5046\n        24       -2542.4414          +2.0353\n        25       -2540.6170          +1.8243\n        26       -2539.7584          +0.8586\n        27       -2539.2140          +0.5444\n        28       -2538.7231          +0.4909\n        29       -2538.2499          +0.4731\n        30       -2537.7818          +0.4681\n        31       -2537.3115          +0.4704\n        32       -2536.8378          +0.4736\n        33       -2536.3626          +0.4752\n        34       -2535.8741          +0.4885\n        35       -2535.3121          +0.5620\n        36       -2534.4952          +0.8169\n        37       -2533.1193          +1.3758\n        38       -2531.5634          +1.5559\n        39       -2530.7138          +0.8496\n        40       -2530.2576          +0.4562\n        41       -2529.8793          +0.3783\n        42       -2529.5141          +0.3651\n        43       -2529.1541          +0.3601\n        44       -2528.8012          +0.3528\n        45       -2528.4599          +0.3413\n        46       -2528.1335          +0.3264\n        47       -2527.8213          +0.3121\n        48       -2527.5091          +0.3123\n        49       -2527.1168          +0.3923\n        50       -2526.1432          +0.9735\n        51       -2523.2692          +2.8740\n        52       -2520.7753          +2.4939\n        53       -2519.7891          +0.9862\n        54       -2519.3051          +0.4840\n        55       -2518.9796          +0.3255\n        56       -2518.7192          +0.2604\n        57       -2518.4893          +0.2299\n        58       -2518.2717          +0.2176\n        59       -2518.0521          +0.2196\n        60       -2517.8145          +0.2376\n        61       -2517.5396          +0.2749\n        62       -2517.2222          +0.3174\n        63       -2516.9172          +0.3051\n        64       -2516.7081          +0.2091\n        65       -2516.5863          +0.1218\n        66       -2516.5026          +0.0838\n        67       -2516.4357          +0.0669\n        68       -2516.3793          +0.0564\n        69       -2516.3306          +0.0487\n        70       -2516.2879          +0.0427\n        71       -2516.2501          +0.0378\n        72       -2516.2163          +0.0337\n        73       -2516.1860          +0.0303\n        74       -2516.1586          +0.0274\n        75       -2516.1338          +0.0248\n        76       -2516.1112          +0.0226\n        77       -2516.0906          +0.0206\n        78       -2516.0717          +0.0189\n        79       -2516.0544          +0.0173\n        80       -2516.0385          +0.0159\n        81       -2516.0238          +0.0147\n        82       -2516.0102          +0.0136\n        83       -2515.9976          +0.0126\n        84       -2515.9860          +0.0117\n        85       -2515.9751          +0.0109\n        86       -2515.9650          +0.0101\nTraining done\n        87       -2515.9556          +0.0094\n"
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=5*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ], ])\n",
    "\n",
    "Xcth = np.concatenate(trainset['nguoi'])\n",
    "lengths = list([len(x) for x in trainset['nguoi']])\n",
    "print(\"training class\", 'nguoi')\n",
    "print(Xcth.shape, lengths, len(lengths))\n",
    "hmm.fit(Xcth, lengths=lengths)\n",
    "models['nguoi'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models cho 'trong' 6x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training class trong\n(2116, 1) [30, 26, 23, 29, 28, 31, 22, 16, 21, 22, 19, 20, 33, 28, 25, 24, 25, 23, 26, 19, 21, 38, 29, 34, 18, 22, 19, 23, 17, 19, 20, 23, 24, 21, 33, 20, 20, 25, 21, 21, 25, 25, 24, 19, 28, 30, 20, 22, 21, 19, 16, 22, 26, 17, 25, 18, 31, 20, 21, 28, 20, 20, 28, 21, 24, 21, 23, 29, 22, 22, 23, 39, 21, 28, 20, 21, 22, 24, 21, 23, 22, 22, 22, 20, 15, 23, 25, 29, 22, 29] 90\n         1       -5378.6266             +nan\n         2       -3130.3641       +2248.2625\n         3       -2628.7277        +501.6364\n         4       -2444.1444        +184.5833\n         5       -2373.7390         +70.4054\n         6       -2333.1698         +40.5692\n         7       -2291.8468         +41.3230\n         8       -2264.2696         +27.5772\n         9       -2246.3244         +17.9452\n        10       -2234.6712         +11.6532\n        11       -2228.2456          +6.4256\n        12       -2225.0402          +3.2054\n        13       -2223.3473          +1.6929\n        14       -2222.3085          +1.0388\n        15       -2221.5985          +0.7100\n        16       -2221.0959          +0.5026\n        17       -2220.7408          +0.3551\n        18       -2220.4932          +0.2476\n        19       -2220.3229          +0.1702\n        20       -2220.2071          +0.1158\n        21       -2220.1287          +0.0784\n        22       -2220.0755          +0.0532\n        23       -2220.0390          +0.0365\n        24       -2220.0133          +0.0256\n        25       -2219.9948          +0.0185\n        26       -2219.9810          +0.0139\n        27       -2219.9702          +0.0108\nTraining done\n        28       -2219.9615          +0.0087\n"
    }
   ],
   "source": [
    "hmm = hmmlearn.hmm.MultinomialHMM(n_components=3*3, random_state=0, n_iter=1000, verbose=True, init_params='e', params='ste')\n",
    "hmm.startprob_ = np.array([0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ])\n",
    "hmm.transmat_ =np.array([\n",
    "    [0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, 0.0, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.2, 0.1, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.3, ],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ],])\n",
    "\n",
    "Xvn = np.concatenate(trainset['trong'])\n",
    "lengths = list([len(x) for x in trainset['trong']])\n",
    "print(\"training class\", 'trong')\n",
    "print(Xvn.shape, lengths, len(lengths))\n",
    "hmm.fit(Xvn, lengths=lengths)\n",
    "models['trong'] = hmm\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Testing\ncothe {'cothe': -148.9903247989622, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -279.96886627846396, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -197.0668714291678, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -170.85403310996097, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -386.7590144247123, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -152.68388060095563, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -171.67970783313208, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -412.18677067293686, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -193.49999944515793, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -414.5356327693497, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -384.42273334257544, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -171.83253674657368, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\ncothe {'cothe': -226.00059548372187, 'da': -inf, 'duoc': -inf, 'nguoi': -inf, 'trong': -inf} predict: cothe\nda {'cothe': -28.429349479945387, 'da': -26.074428181245246, 'duoc': -29.813047226099002, 'nguoi': -46.4591625588682, 'trong': -56.82986030921022} predict: da\nda {'cothe': -27.636649428239302, 'da': -20.960245226135395, 'duoc': -24.92304483863417, 'nguoi': -26.97914587964562, 'trong': -38.35699376752236} predict: da\nda {'cothe': -364.16464995117326, 'da': -26.97781839354868, 'duoc': -34.80607028046516, 'nguoi': -33.13737409507789, 'trong': -170.67202220222126} predict: da\nda {'cothe': -28.11357006754135, 'da': -23.53182470856764, 'duoc': -26.273280124805282, 'nguoi': -15.355535385520716, 'trong': -68.78487784066539} predict: nguoi\nda {'cothe': -29.336323887485865, 'da': -18.717418309407275, 'duoc': -23.671172850811203, 'nguoi': -24.162720856689432, 'trong': -48.713469246877} predict: da\nda {'cothe': -31.06795211973671, 'da': -18.392994957513828, 'duoc': -22.63433446825767, 'nguoi': -24.791317978499997, 'trong': -30.10624604901766} predict: da\nda {'cothe': -31.180155259867483, 'da': -23.074287098216914, 'duoc': -28.4542051009284, 'nguoi': -20.898288363778065, 'trong': -33.984701677662486} predict: nguoi\nda {'cothe': -40.492856171939096, 'da': -26.37992224376188, 'duoc': -22.430546313892197, 'nguoi': -35.92283694836947, 'trong': -35.874638543526615} predict: duoc\nda {'cothe': -45.405461339056835, 'da': -26.480693240430114, 'duoc': -30.564332298051518, 'nguoi': -69.62879986689742, 'trong': -57.472114689428764} predict: da\nda {'cothe': -45.405461339056835, 'da': -26.480693240430114, 'duoc': -30.564332298051518, 'nguoi': -69.62879986689742, 'trong': -57.472114689428764} predict: da\nduoc {'cothe': -33.0172514282641, 'da': -21.400510429177242, 'duoc': -27.402168635429685, 'nguoi': -30.12865229934399, 'trong': -37.19004915378084} predict: da\nduoc {'cothe': -35.1104025617791, 'da': -61.869755052773854, 'duoc': -44.336303371580144, 'nguoi': -inf, 'trong': -264.3704626115497} predict: cothe\nduoc {'cothe': -27.86835072702772, 'da': -23.96136600202548, 'duoc': -21.79824556584446, 'nguoi': -21.292430525750905, 'trong': -45.34277336093305} predict: nguoi\nduoc {'cothe': -356.0149336891355, 'da': -35.14556147488729, 'duoc': -35.077993462115586, 'nguoi': -217.62876076413028, 'trong': -691.9394419950316} predict: duoc\nduoc {'cothe': -59.81406759582398, 'da': -37.06523168872607, 'duoc': -28.985932115277656, 'nguoi': -169.40293159752443, 'trong': -45.8664198901024} predict: duoc\nduoc {'cothe': -46.70798176301927, 'da': -30.79238452967973, 'duoc': -21.672441966971093, 'nguoi': -86.36023806184107, 'trong': -43.167984189159384} predict: duoc\nduoc {'cothe': -50.40829926559453, 'da': -34.99212148993489, 'duoc': -26.537360917012002, 'nguoi': -116.37456972065719, 'trong': -54.631542628893115} predict: duoc\nduoc {'cothe': -48.699817655500595, 'da': -41.2369884547319, 'duoc': -20.90456602228309, 'nguoi': -152.06540125414637, 'trong': -49.420034515279916} predict: duoc\nduoc {'cothe': -81.9288742513416, 'da': -46.95430032878728, 'duoc': -27.92294798058718, 'nguoi': -156.29884037483046, 'trong': -50.39970033937143} predict: duoc\nduoc {'cothe': -48.51708669726461, 'da': -39.57421105589846, 'duoc': -31.86526670697012, 'nguoi': -inf, 'trong': -86.1288126175256} predict: duoc\nnguoi {'cothe': -47.53382784994812, 'da': -33.09111806276616, 'duoc': -36.16711648620036, 'nguoi': -18.124561914745065, 'trong': -96.17597791008428} predict: nguoi\nnguoi {'cothe': -48.435814280043914, 'da': -43.601959203575895, 'duoc': -38.8282713674535, 'nguoi': -33.795625168529035, 'trong': -101.15243677892968} predict: nguoi\nnguoi {'cothe': -35.537713287712634, 'da': -28.57209529608227, 'duoc': -29.26307273777249, 'nguoi': -18.36649543986136, 'trong': -78.23770955605106} predict: nguoi\nnguoi {'cothe': -40.975041809080054, 'da': -27.740349076920904, 'duoc': -31.547779560637775, 'nguoi': -29.96869713927588, 'trong': -54.845228846384984} predict: da\nnguoi {'cothe': -30.85012991966483, 'da': -22.370643455969937, 'duoc': -20.534272700889673, 'nguoi': -17.903459382378177, 'trong': -54.672882370797666} predict: nguoi\nnguoi {'cothe': -36.268174977818155, 'da': -33.12251185617461, 'duoc': -39.3545120884336, 'nguoi': -25.70200653186769, 'trong': -81.03851951274159} predict: nguoi\nnguoi {'cothe': -41.391401163304664, 'da': -32.43605764480105, 'duoc': -29.981008279431926, 'nguoi': -20.621350088097795, 'trong': -87.91676050124936} predict: nguoi\nnguoi {'cothe': -39.2670972709233, 'da': -34.085820575360344, 'duoc': -31.120977399226526, 'nguoi': -19.57946548916594, 'trong': -82.37049195723887} predict: nguoi\nnguoi {'cothe': -36.80547051569799, 'da': -43.04966386895, 'duoc': -47.46982602488692, 'nguoi': -20.92666820922199, 'trong': -140.7176455538946} predict: nguoi\nnguoi {'cothe': -34.427775784867144, 'da': -31.028137999812934, 'duoc': -29.30115807742414, 'nguoi': -32.07691762954882, 'trong': -50.25721253209368} predict: duoc\ntrong {'cothe': -65.53970403357894, 'da': -44.48854627100817, 'duoc': -61.11497217913027, 'nguoi': -87.33462063396439, 'trong': -52.98669240355292} predict: da\ntrong {'cothe': -75.64158612536842, 'da': -37.40630360139441, 'duoc': -45.078782206293305, 'nguoi': -62.09147512749747, 'trong': -25.269031866549014} predict: trong\ntrong {'cothe': -54.20047289202055, 'da': -38.11757472271408, 'duoc': -42.572486516623215, 'nguoi': -72.30735335614877, 'trong': -28.567944926095468} predict: trong\ntrong {'cothe': -57.161052376781356, 'da': -35.01683587395679, 'duoc': -38.23669213419305, 'nguoi': -43.74396485901927, 'trong': -40.41261826256804} predict: da\ntrong {'cothe': -55.63761203749082, 'da': -44.80099146449133, 'duoc': -37.493429444965535, 'nguoi': -61.94297135808288, 'trong': -117.48900397622523} predict: duoc\ntrong {'cothe': -69.60829472207293, 'da': -50.192555797059086, 'duoc': -175.11629786197935, 'nguoi': -inf, 'trong': -32.289178359408865} predict: trong\ntrong {'cothe': -79.03849021421168, 'da': -43.468595633445716, 'duoc': -105.16748514775657, 'nguoi': -66.19957008427296, 'trong': -93.50333213470405} predict: da\ntrong {'cothe': -121.4683115504221, 'da': -94.61577914237236, 'duoc': -97.10267476638758, 'nguoi': -inf, 'trong': -99.04231214063768} predict: da\ntrong {'cothe': -63.31626080668119, 'da': -36.79159095491656, 'duoc': -220.18777549604442, 'nguoi': -62.69317214111793, 'trong': -63.486719666786506} predict: da\ntrong {'cothe': -71.08799153213589, 'da': -40.588611247008274, 'duoc': -42.427155602835576, 'nguoi': -71.23028633756955, 'trong': -39.263039479953385} predict: trong\n"
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "n_correct = {'cothe': 0, 'da': 0, 'duoc': 0, 'nguoi': 0,'trong': 0}\n",
    "for true_cname in class_names:\n",
    "    for O in testset[true_cname]:\n",
    "        score = {cname: model.score(O, [len(O)]) for cname, model in models.items()}\n",
    "        if (true_cname == max(score, key=score.get)): n_correct[true_cname] += 1\n",
    "        print(true_cname, score, 'predict:', max(score, key=score.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: cothe 1.0\nAccuracy: da 0.7\nAccuracy: duoc 0.7\nAccuracy: nguoi 0.8\nAccuracy: trong 0.4\n"
    }
   ],
   "source": [
    "for cname in class_names:\n",
    "    print('Accuracy:', cname, n_correct[cname]/n_test[cname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Accuracy: 0.8380952380952381\n"
     ]
    }
   ],
   "source": [
    "print('All Accuracy:', sum(n_correct.values())/sum(n_test.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cothe': 25, 'da': 20, 'duoc': 20, 'nguoi': 20, 'trong': 20}\n"
     ]
    }
   ],
   "source": [
    "print(n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.around(models['trong'].transmat_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}